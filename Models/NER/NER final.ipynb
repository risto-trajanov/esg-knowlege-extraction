{"cells":[{"cell_type":"markdown","metadata":{"id":"iZJGv0aPChwl"},"source":["# Spacy"]},{"cell_type":"code","source":["import json\n","import traceback\n","import re\n","import spacy\n","from spacy.tokens import DocBin\n","from tqdm import tqdm\n","from spacy.util import filter_spans\n","import locale"],"metadata":{"id":"eS56lNwucCT5","executionInfo":{"status":"ok","timestamp":1683164857510,"user_tz":300,"elapsed":86,"user":{"displayName":"Matias Romero","userId":"01974732191892393183"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r9zCrxrkEHto"},"outputs":[],"source":["\n","def get_entites_spacy(file_name):\n","    \"\"\"Extract the entities for NER traineing from Label Studio json data format for scipy fine tuning.\n","\n","    Args:\n","        file_name (str): JSON File location.\n","\n","    Returns:\n","        list: Extracted entites in the format [(text, {\"entities\":[(start, end, label)]})]\n","    \"\"\"\n","    # labels = ['Organization', 'Asset', 'Person', 'Investor']\n","    esg_map = {'Soc': 'Social', 'Env': 'Environmental', 'Gov': 'Governance'}\n","    documents = []\n","    # Open the JSONL file for reading\n","    with open(file_name, 'r', encoding='utf-8') as jsonl_file:\n","        # Iterate over the lines in the file\n","        data = json.load(jsonl_file)\n","        for item in data:\n","            text = item['data']['text']\n","\n","            entities = []\n","            # Parse each line as a JSON object\n","            for entry in item['annotations']:\n","                for res in entry['result']:\n","                    try:\n","                        boundaries = []\n","                    \n","                        if res['type'] == 'labels':\n","                            value = res['value']\n","                            from_name = res['from_name']\n","                            ner = from_name.split('-')[1]\n","                            \n","                            if ner == 'General':\n","                                continue\n","                                if value['labels'][0] in labels:\n","                                    ner = value['labels'][0]\n","                            else:\n","                                ner = esg_map[ner]\n","                            boundaries.append(value['start'])\n","                            boundaries.append(value['end'])\n","                            entities.append((boundaries[0], boundaries[1], ner))\n","                    except Exception as e:\n","                        print(res)\n","                        print(traceback.print_exc())\n","                        break\n","            \n","            documents.append({'text': text, 'entities': entities})\n","    return documents"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2nwnN4ISChwn"},"outputs":[],"source":["# import extract_data as ex\n","\n","documents = []\n","documents += get_entites_spacy('chev_data.json')\n","documents += get_entites_spacy('chev_data2.json')"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1683153300378,"user":{"displayName":"Matias Romero","userId":"01974732191892393183"},"user_tz":300},"id":"RGUfkczFmYkV","outputId":"4d87466d-b78f-44dc-e864-8b6ea4338144"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1240"]},"metadata":{},"execution_count":1}],"source":["with open('./ner_data_spacy.txt', 'r') as f:\n","    data = json.load(f)\n","\n","\n","def entity_boundaries(data):\n","    #df_data = pd.DataFrame(columns=['data'])\n","    lst_data = []\n","    for idx in range(len(data)):\n","        text = data[idx]['text']\n","        entities = data[idx]['entities']\n","        ent_w_loc = []\n","\n","        for entity in entities:\n","            if entity['entity'] not in ['Environmental', 'Social', 'Governance']:\n","              continue\n","            pattern = re.compile(entity['value'])\n","            m_val = pattern.search(text)\n","            if m_val is not None:\n","                ent_w_loc.append((m_val.start(), m_val.end(), entity['entity']))\n","                \n","                \n","        if len(ent_w_loc)!=0:\n","          #df_data = pd.concat([df_data, pd.DataFrame(\n","          #    {'data':[(text, {'entities':ent_w_loc})]})], ignore_index=True)\n","            lst_data.append(({'text': text, 'entities':ent_w_loc}))\n","\n","    return lst_data\n","\n","lst_data=entity_boundaries(data)\n","len(lst_data)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"qK5Sd4pXChwn","executionInfo":{"status":"ok","timestamp":1683153343460,"user_tz":300,"elapsed":14776,"user":{"displayName":"Matias Romero","userId":"01974732191892393183"}}},"outputs":[],"source":["nlp = spacy.blank(\"en\") # load a new spacy model\n","doc_bin = DocBin()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":401,"status":"ok","timestamp":1683153382164,"user":{"displayName":"Matias Romero","userId":"01974732191892393183"},"user_tz":300},"id":"lqDKolwxChwn","outputId":"3cab1617-ac9c-41cc-b521-3a3a3a58d97f"},"outputs":[{"output_type":"stream","name":"stderr","text":[" 61%|██████    | 637/1050 [00:00<00:00, 2144.50it/s]"]},{"output_type":"stream","name":"stdout","text":["Skipping entity\n","Skipping entity\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1050/1050 [00:00<00:00, 2285.84it/s]\n"]}],"source":["training_data = documents\n","for training_example  in tqdm(training_data[:1050]): \n","    # print(training_example['text'])\n","    text = training_example['text']\n","    labels = training_example['entities']\n","    doc = nlp.make_doc(text) \n","    ents = []\n","    for start, end, label in labels:\n","        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n","        if span is None:\n","            print(\"Skipping entity\")\n","        else:\n","            ents.append(span)\n","    filtered_ents = filter_spans(ents)\n","    doc.ents = filtered_ents \n","    doc_bin.add(doc)\n","\n","doc_bin.to_disk(\"train.spacy\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":198,"status":"ok","timestamp":1683153387664,"user":{"displayName":"Matias Romero","userId":"01974732191892393183"},"user_tz":300},"id":"xjBQtBey1vcH","outputId":"f71a3ed6-5ac1-44f8-f8e8-57804d834d1e"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 190/190 [00:00<00:00, 4131.21it/s]\n"]}],"source":["training_data = documents\n","for training_example  in tqdm(training_data[1050:]): \n","    # print(training_example['text'])\n","    text = training_example['text']\n","    labels = training_example['entities']\n","    doc = nlp.make_doc(text) \n","    ents = []\n","    for start, end, label in labels:\n","        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n","        if span is None:\n","            print(\"Skipping entity\")\n","        else:\n","            ents.append(span)\n","    filtered_ents = filter_spans(ents)\n","    doc.ents = filtered_ents \n","    doc_bin.add(doc)\n","\n","doc_bin.to_disk(\"val.spacy\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":106,"status":"ok","timestamp":1683153395573,"user":{"displayName":"Matias Romero","userId":"01974732191892393183"},"user_tz":300},"id":"V9DT0RH0EaTm","outputId":"f6904cec-868d-4f27-e5f6-6f9789b7c5c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["ANSI_X3.4-1968\n"]}],"source":["print(locale.getpreferredencoding())"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"eGKCesUMEhup","executionInfo":{"status":"ok","timestamp":1683153399026,"user_tz":300,"elapsed":87,"user":{"displayName":"Matias Romero","userId":"01974732191892393183"}}},"outputs":[],"source":["locale.getpreferredencoding = lambda: \"UTF-8\""]},{"cell_type":"code","execution_count":24,"metadata":{"id":"Zdjb4ub8FQTd","executionInfo":{"status":"ok","timestamp":1683164857165,"user_tz":300,"elapsed":4758,"user":{"displayName":"Matias Romero","userId":"01974732191892393183"}}},"outputs":[],"source":["!pip install spacy-transformers -qq"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13117,"status":"ok","timestamp":1683153524248,"user":{"displayName":"Matias Romero","userId":"01974732191892393183"},"user_tz":300},"id":"3NqvJnkxLBC4","outputId":"c03a0ddf-2861-486e-8710-f639506a7e0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-03 22:38:34.557559: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n","\u001b[38;5;2m✔ Saved config\u001b[0m\n","config.cfg\n","You can now add your data and train your pipeline:\n","python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"]}],"source":["!python -m spacy init fill-config ./base_config.cfg config.cfg "]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32091,"status":"ok","timestamp":1683153586971,"user":{"displayName":"Matias Romero","userId":"01974732191892393183"},"user_tz":300},"id":"XJJXk3uvx4vH","outputId":"1a178bce-8497-4547-a14f-9304754c550d"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-03 22:39:18.966308: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-lg==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.5.0) (3.5.2)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.6)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.8)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.65.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.27.1)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (67.7.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.9)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.7)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (23.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.15)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.2)\n","Installing collected packages: en-core-web-lg\n","Successfully installed en-core-web-lg-3.5.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_lg')\n"]}],"source":["!python3 -m spacy download en_core_web_lg"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gy19aLNxChwo","outputId":"949a9e15-0513-4770-bd66-14d324f29939","executionInfo":{"status":"ok","timestamp":1683157735226,"user_tz":300,"elapsed":4141254,"user":{"displayName":"Matias Romero","userId":"01974732191892393183"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-03 22:39:57.649253: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[38;5;2m✔ Created output directory: models_05_02\u001b[0m\n","\u001b[38;5;4mℹ Saving to output directory: models_05_02\u001b[0m\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2023-05-03 22:40:09,929] [INFO] Set up nlp object from config\n","[2023-05-03 22:40:09,947] [INFO] Pipeline: ['transformer', 'ner']\n","[2023-05-03 22:40:09,951] [INFO] Created vocabulary\n","[2023-05-03 22:40:09,954] [INFO] Finished initializing nlp object\n","Downloading (…)lve/main/config.json: 100% 481/481 [00:00<00:00, 2.75MB/s]\n","Downloading (…)olve/main/vocab.json: 100% 899k/899k [00:00<00:00, 17.5MB/s]\n","Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 146MB/s]\n","Downloading (…)/main/tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 57.2MB/s]\n","Downloading pytorch_model.bin: 100% 501M/501M [00:05<00:00, 86.6MB/s]\n","Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[2023-05-03 22:40:42,062] [INFO] Initialized pipeline components: ['transformer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  --------  ------  ------  ------  ------\n","  0       0        2719.23    568.87    0.23    0.22    0.25    0.00\n"," 11     200      113692.55  67095.94   32.12   40.35   26.68    0.32\n"," 23     400       32177.84  26505.51   78.60   78.38   78.83    0.79\n"," 35     600       15263.89  11629.54   85.86   85.63   86.09    0.86\n"," 47     800       10016.05   6939.21   85.23   84.63   85.84    0.85\n"," 58    1000       11234.16   7205.65   88.86   88.99   88.73    0.89\n"," 70    1200        5041.10   3512.28   89.55   88.98   90.13    0.90\n"," 82    1400        4421.07   2979.75   89.68   89.38   89.99    0.90\n"," 94    1600        3998.39   2488.82   90.07   90.29   89.84    0.90\n","105    1800       11549.00   6166.32   90.09   89.80   90.38    0.90\n","117    2000        2027.19   1314.98   91.12   90.83   91.42    0.91\n","129    2200        1492.98    997.72   91.18   91.44   90.92    0.91\n","141    2400         678.52    554.81   91.53   91.49   91.56    0.92\n","152    2600         636.46    525.24   91.92   91.73   92.10    0.92\n","164    2800         437.14    360.01   91.58   91.00   92.17    0.92\n","176    3000         842.63    580.60   91.29   90.89   91.70    0.91\n","188    3200         494.89    325.03   91.85   91.82   91.88    0.92\n","200    3400         428.76    314.17   91.68   91.70   91.67    0.92\n","211    3600         256.76    223.34   91.28   91.01   91.56    0.91\n","223    3800         340.95    257.48   91.71   91.25   92.17    0.92\n","235    4000         205.36    171.03   91.31   90.72   91.92    0.91\n","247    4200         265.45    213.49   91.94   91.89   91.99    0.92\n","258    4400         183.17    123.30   91.79   91.44   92.13    0.92\n","270    4600         163.76    124.54   91.89   91.82   91.95    0.92\n","282    4800         147.20    107.90   92.02   92.11   91.92    0.92\n","294    5000         182.09    147.64   91.65   91.45   91.85    0.92\n","305    5200         203.40    150.82   91.53   91.46   91.60    0.92\n","317    5400         180.19    130.41   91.73   91.38   92.10    0.92\n","329    5600         127.78     95.50   91.90   91.91   91.88    0.92\n","341    5800         145.31    100.65   91.19   90.78   91.60    0.91\n","352    6000         176.14    131.70   91.88   91.70   92.06    0.92\n","364    6200         189.29    115.36   91.86   91.85   91.88    0.92\n","376    6400         139.75     97.88   91.89   91.40   92.38    0.92\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","models_05_02/model-last\n"]}],"source":["!python -m spacy train config.cfg --gpu-id 0 --output ./models_05_02 --paths.train ./train.spacy --paths.dev ./val.spacy "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cxOVIlq3WaKI"},"outputs":[],"source":["#Final model uploaded to Huggingface\n","!pip install https://huggingface.co/msr10/en_esg_ner/resolve/main/en_esg_ner-any-py3-none-any.whl\n","\n","# Using spacy.load().\n","import spacy\n","nlp = spacy.load(\"en_esg_ner\")"]},{"cell_type":"code","source":["doc = nlp(\"These concerns reflect a converging consensus by policymakers, investors, and companies on growing climate risk, the need to limit global temperature increase to 1.5° C (net zero global greenhouse gas (GHG) emissions by 2050),5 and the impact of such actions to companies.\")\n","\n","colors = {\"Social\": \"#F67DE3\", \"Governance\": \"#7DF6D9\", \"Environmental\":\"#a6e22d\"}\n","options = {\"colors\": colors} \n","\n","spacy.displacy.render(doc, style=\"ent\", options= options, jupyter=True)"],"metadata":{"id":"x8uyP_ya9Agr","executionInfo":{"status":"aborted","timestamp":1683164349282,"user_tz":300,"elapsed":6,"user":{"displayName":"Matias Romero","userId":"01974732191892393183"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wTgt-deA9R4C"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1qatli_rklvReSm19UM2pMfwFu5ljs4PD","timestamp":1683153241236}]},"gpuClass":"standard","kernelspec":{"display_name":"myenv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}