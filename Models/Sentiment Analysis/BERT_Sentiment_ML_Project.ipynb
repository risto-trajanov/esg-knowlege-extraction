{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFWscK_lh4bc",
        "outputId": "5c7dba19-7df4-4b8b-b234-488ee932a2ed"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets\n",
        "# !pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0XL1X9fPiZL0"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "from transformers import EvalPrediction\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xkWiOskHmmys"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "json_data={}\n",
        "\n",
        "for iter in range(3):\n",
        "\n",
        "    # Read the JSON data from the file\n",
        "    with open('202'+str(iter)+'data.txt', 'r') as f:\n",
        "        json_data[iter] = json.load(f)\n",
        "\n",
        "# Create an empty dataframe with two columns: text and labels\n",
        "df = pd.DataFrame(columns=['Text', 'labels'])\n",
        "\n",
        "# Loop through each item in the JSON data and append a new row to the dataframe\n",
        "for key in json_data.keys():\n",
        "    for item in json_data[key]:\n",
        "        df = df.append({\n",
        "            'Text': item['text'],\n",
        "            'labels': item['labels']\n",
        "        }, ignore_index=True)\n",
        "\n",
        "# Print the resulting dataframe\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "labels_matrix = mlb.fit_transform(df['labels'])\n",
        "\n",
        "# Create a new dataframe with the binary matrix and column names from the MultiLabelBinarizer\n",
        "labels_df = pd.DataFrame(labels_matrix, columns=mlb.classes_)\n",
        "\n",
        "# Concatenate the new dataframe with the original dataframe\n",
        "df = pd.concat([df, labels_df], axis=1)\n",
        "\n",
        "df['sum_one_hot'] = df.iloc[:, 2:].sum(axis=1)\n",
        "df = df[df['sum_one_hot']>0]\n",
        "\n",
        "df = df.drop(['labels', 'sum_one_hot'], axis=1)\n",
        "\n",
        "dataset = Dataset.from_pandas(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "e0b9094c0b744be4aea290900eb2f88a",
            "1da97a22a3124fa4bcdac07e755b9d70",
            "62fd68a5ea564c509a0ae7a66979b172",
            "737f306e12214ea485baafc4812da102",
            "e17b08b22be04e8a9eea8a14eba2acc7",
            "f85148fdcbc442a0ae07bd72a1734b92",
            "37919a76128745b3b068805483e6f5f9",
            "a0c2538c491b46d796ed0d17ea37b9ae",
            "7ff3243dc1964d869e7d32995ca80c21",
            "2274c90baa1e4bf69fcd2efbb3b7b1a8",
            "ca72659a41874f51a169595636ca62e4",
            "f9f7136b1ec04d7e9e166f32e77fdc49",
            "3c794ab0e38f4afcb8095e4a801f6ed2",
            "de361c7c877b41af82e65851fe6f9392",
            "ef894fd2d7a6448191d19a98baec1510",
            "5baaa3c512594058821c3e58406c9fa6",
            "2e2803a3b918404e93cfa17545ddbd93",
            "8da663ef0a914383852cedbbe358f3f9",
            "cf23db3bcf2d41bd96a17da6b9a6e6f5",
            "4ab43117e93d4baf946961aeb08fca93",
            "0fad0845d75c414ab9008499e02fd22f",
            "5ef4ef9e2b98458ebb4a93188d32f204"
          ]
        },
        "id": "lgjExUc6hoZI",
        "outputId": "2ffb7098-95a6-4e36-d3ee-ac9a4127c928"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at C:\\Users\\Risto Trajanov/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at C:\\Users\\Risto Trajanov/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\vocab.txt\n",
            "loading file tokenizer.json from cache at C:\\Users\\Risto Trajanov/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at C:\\Users\\Risto Trajanov/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\tokenizer_config.json\n",
            "loading configuration file config.json from cache at C:\\Users\\Risto Trajanov/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at C:\\Users\\Risto Trajanov/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"Environmental Negative\",\n",
            "    \"1\": \"Environmental Neutral\",\n",
            "    \"2\": \"Environmental Positive\",\n",
            "    \"3\": \"Social Negative\",\n",
            "    \"4\": \"Social Neutral\",\n",
            "    \"5\": \"Social Positive\",\n",
            "    \"6\": \"Governance Negative\",\n",
            "    \"7\": \"Governance Neutral\",\n",
            "    \"8\": \"Governance Positive\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"Environmental Negative\": 0,\n",
            "    \"Environmental Neutral\": 1,\n",
            "    \"Environmental Positive\": 2,\n",
            "    \"Governance Negative\": 6,\n",
            "    \"Governance Neutral\": 7,\n",
            "    \"Governance Positive\": 8,\n",
            "    \"Social Negative\": 3,\n",
            "    \"Social Neutral\": 4,\n",
            "    \"Social Positive\": 5\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"multi_label_classification\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at C:\\Users\\Risto Trajanov/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Define your labels\n",
        "labels = [\"Environmental Negative\", \"Environmental Neutral\", \"Environmental Positive\", \"Social Negative\", \"Social Neutral\", \n",
        "          \"Social Positive\", \"Governance Negative\", \"Governance Neutral\", \"Governance Positive\"]\n",
        "\n",
        "# Create label conversion dictionaries\n",
        "id2label = {idx: label for idx, label in enumerate(labels)}\n",
        "label2id = {label: idx for idx, label in enumerate(labels)}\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Convert the data dictionary into a list of dictionaries\n",
        "#data_list = [{\"ID\": id, \"Text\": item[\"text\"], **{label: int(label in item[\"labels\"]) for label in labels}} for id, item in data.items()]\n",
        "\n",
        "# Convert the data list into a Dataset\n",
        "#dataset = Dataset.from_dict({k: [d[k] for d in data_list] for k in data_list[0]})\n",
        "\n",
        "# Split dataset into training and validation sets\n",
        "dataset = dataset.train_test_split(test_size=0.1)\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_data(examples):\n",
        "    text = examples[\"Text\"]\n",
        "    encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
        "    labels_matrix = np.zeros((len(text), len(labels)))\n",
        "\n",
        "    for idx, label in enumerate(labels):\n",
        "        labels_matrix[:, idx] = labels_batch[label]\n",
        "\n",
        "    encoding[\"labels\"] = labels_matrix.tolist()\n",
        "\n",
        "    return encoding\n",
        "\n",
        "# Preprocess the dataset\n",
        "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)\n",
        "encoded_dataset.set_format(\"torch\")\n",
        "\n",
        "# Load the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                           problem_type=\"multi_label_classification\",\n",
        "                                                           num_labels=len(labels),\n",
        "                                                           id2label=id2label,\n",
        "                                                           label2id=label2id)\n",
        "\n",
        "#Evaluate function still in process\n",
        "def evaluate(model, encoded_dataset):\n",
        "    input_ids = encoded_dataset[\"input_ids\"]\n",
        "    attention_mask = encoded_dataset[\"attention_mask\"]\n",
        "    labels = encoded_dataset[\"labels\"]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_ids, attention_mask=attention_mask).logits\n",
        "        sigmoid = torch.nn.Sigmoid()\n",
        "        probs = sigmoid(logits)\n",
        "\n",
        "    threshold = 0.5\n",
        "    predicted_labels = (probs >= threshold).int()\n",
        "\n",
        "    f1 = f1_score(labels, predicted_labels, average=\"micro\")\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBlb_0PuFjhJ",
        "outputId": "c0b7a22b-f54c-422a-a835-f2063d5a3e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input text: Some companies are investing in green technologies and reducing their environmental impact.\n",
            "Predicted labels: ['Environmental Negative', 'Environmental Neutral', 'Social Neutral', 'Social Positive', 'Governance Positive']\n",
            "Input text: We are committed to supporting strong energy allies who promote democracy.\n",
            "Predicted labels: ['Environmental Negative', 'Environmental Neutral', 'Social Neutral', 'Social Positive', 'Governance Neutral', 'Governance Positive']\n",
            "Input text: Shareholders request the Company to set and publish medium- and long-term targets to reduce the greenhouse gas (GHG) emissions of the Company’s operations and energy products (Scope 1, 2, and 3) consistent with the goal of the Paris Climate Agreement: to limit global warming to well below 2°C above pre-industrial levels and to pursue efforts to limit the temperature increase to 1.5°C.\n",
            "Predicted labels: ['Environmental Neutral', 'Social Neutral', 'Social Positive', 'Governance Neutral', 'Governance Positive']\n"
          ]
        }
      ],
      "source": [
        "#tokenized_inputs = encoded_dataset[\"test\"]\n",
        "\n",
        "# Define input texts\n",
        "input_texts = [\n",
        "    \"Some companies are investing in green technologies and reducing their environmental impact.\",\n",
        "    \"We are committed to supporting strong energy allies who promote democracy.\",\n",
        "    \"Shareholders request the Company to set and publish medium- and long-term targets to reduce the greenhouse gas (GHG) emissions of the Company’s operations and energy products (Scope 1, 2, and 3) consistent with the goal of the Paris Climate Agreement: to limit global warming to well below 2°C above pre-industrial levels and to pursue efforts to limit the temperature increase to 1.5°C.\"\n",
        "]\n",
        "\n",
        "# Tokenize input texts\n",
        "tokenized_inputs = tokenizer.batch_encode_plus(input_texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(**tokenized_inputs)[0]\n",
        "\n",
        "# Convert logits to probabilities using sigmoid\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "probs = sigmoid(logits)\n",
        "\n",
        "# Get predicted labels based on probabilities\n",
        "threshold = 0.5\n",
        "predicted_labels = []\n",
        "\n",
        "for i in range(len(input_texts)):\n",
        "    predictions = (probs[i] >= threshold).tolist()\n",
        "    predicted_labels.append([labels[idx] for idx, value in enumerate(predictions) if value])\n",
        "\n",
        "# Print predicted labels\n",
        "for i in range(len(input_texts)):\n",
        "    print(f\"Input text: {input_texts[i]}\")\n",
        "    print(f\"Predicted labels: {predicted_labels[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh-t2TLPd9bL",
        "outputId": "bacb860f-af26-4343-945e-7744cfcf3793"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Text', 'Environmental Negative', 'Environmental Neutral', 'Environmental Positive', 'Governance Negative', 'Governance Neutral', 'Governance Positive', 'Social Negative', 'Social Neutral', 'Social Positive', '__index_level_0__'],\n",
              "        num_rows: 611\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['Text', 'Environmental Negative', 'Environmental Neutral', 'Environmental Positive', 'Governance Negative', 'Governance Neutral', 'Governance Positive', 'Social Negative', 'Social Neutral', 'Social Positive', '__index_level_0__'],\n",
              "        num_rows: 68\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tq7LsH_S3y0",
        "outputId": "179d311f-2b34-43fc-b057-56da54df608c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Micro-averaged F1 score: 0.2169\n"
          ]
        }
      ],
      "source": [
        "f1 = evaluate(model, encoded_dataset['test'])\n",
        "print(f\"Micro-averaged F1 score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:29xa1cel) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">laced-morning-1</strong> at: <a href='https://wandb.ai/trajanov/sentiment-esg/runs/29xa1cel' target=\"_blank\">https://wandb.ai/trajanov/sentiment-esg/runs/29xa1cel</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20230430_143754-29xa1cel\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:29xa1cel). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.15.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>g:\\Other computers\\My Computer\\Masters\\Rice\\Spring23\\COMP 642\\COMP 642 Project\\Code\\Models\\Sentiment Analysis\\wandb\\run-20230430_144817-z1gwayhw</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/trajanov/sentiment-esg/runs/z1gwayhw' target=\"_blank\">amber-bee-2</a></strong> to <a href='https://wandb.ai/trajanov/sentiment-esg' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/trajanov/sentiment-esg' target=\"_blank\">https://wandb.ai/trajanov/sentiment-esg</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/trajanov/sentiment-esg/runs/z1gwayhw' target=\"_blank\">https://wandb.ai/trajanov/sentiment-esg/runs/z1gwayhw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "run = wandb.init(entity='trajanov', project='sentiment-esg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import gc\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn6ZZu-nTVjM"
      },
      "source": [
        "###Training Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "h9uFi0SjC7OU",
        "outputId": "2fcfe596-d27f-4c14-e115-83f774563448"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "  0%|          | 0/770 [04:34<?, ?it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 611\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 770\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "  0%|          | 0/770 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            " 10%|█         | 77/770 [00:26<03:28,  3.32it/s]***** Running Evaluation *****\n",
            "  Num examples = 68\n",
            "  Batch size = 8\n",
            "\n",
            " 10%|█         | 77/770 [00:27<03:28,  3.32it/s]Saving model checkpoint to bert-finetuned-custom-data\\checkpoint-77\n",
            "Configuration saved in bert-finetuned-custom-data\\checkpoint-77\\config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.33962491154670715, 'eval_f1': 0.4122137404580153, 'eval_roc_auc': 0.6345639878177637, 'eval_accuracy': 0.27941176470588236, 'eval_runtime': 0.8488, 'eval_samples_per_second': 80.11, 'eval_steps_per_second': 10.603, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in bert-finetuned-custom-data\\checkpoint-77\\pytorch_model.bin\n",
            "tokenizer config file saved in bert-finetuned-custom-data\\checkpoint-77\\tokenizer_config.json\n",
            "Special tokens file saved in bert-finetuned-custom-data\\checkpoint-77\\special_tokens_map.json\n",
            " 20%|██        | 154/770 [01:01<03:09,  3.25it/s]***** Running Evaluation *****\n",
            "  Num examples = 68\n",
            "  Batch size = 8\n",
            "\n",
            " 20%|██        | 154/770 [01:02<03:09,  3.25it/s]Saving model checkpoint to bert-finetuned-custom-data\\checkpoint-154\n",
            "Configuration saved in bert-finetuned-custom-data\\checkpoint-154\\config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.2911434769630432, 'eval_f1': 0.4411764705882353, 'eval_roc_auc': 0.6487662378022251, 'eval_accuracy': 0.27941176470588236, 'eval_runtime': 0.8541, 'eval_samples_per_second': 79.62, 'eval_steps_per_second': 10.538, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in bert-finetuned-custom-data\\checkpoint-154\\pytorch_model.bin\n",
            "tokenizer config file saved in bert-finetuned-custom-data\\checkpoint-154\\tokenizer_config.json\n",
            "Special tokens file saved in bert-finetuned-custom-data\\checkpoint-154\\special_tokens_map.json\n",
            " 30%|███       | 231/770 [01:34<02:45,  3.26it/s]***** Running Evaluation *****\n",
            "  Num examples = 68\n",
            "  Batch size = 8\n",
            "\n",
            " 30%|███       | 231/770 [01:35<02:45,  3.26it/s]Saving model checkpoint to bert-finetuned-custom-data\\checkpoint-231\n",
            "Configuration saved in bert-finetuned-custom-data\\checkpoint-231\\config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.25965210795402527, 'eval_f1': 0.5975609756097561, 'eval_roc_auc': 0.7422462552054199, 'eval_accuracy': 0.36764705882352944, 'eval_runtime': 0.854, 'eval_samples_per_second': 79.626, 'eval_steps_per_second': 10.539, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in bert-finetuned-custom-data\\checkpoint-231\\pytorch_model.bin\n",
            "tokenizer config file saved in bert-finetuned-custom-data\\checkpoint-231\\tokenizer_config.json\n",
            "Special tokens file saved in bert-finetuned-custom-data\\checkpoint-231\\special_tokens_map.json\n",
            " 40%|████      | 308/770 [02:08<02:23,  3.22it/s]***** Running Evaluation *****\n",
            "  Num examples = 68\n",
            "  Batch size = 8\n",
            "\n",
            " 40%|████      | 308/770 [02:08<02:23,  3.22it/s]Saving model checkpoint to bert-finetuned-custom-data\\checkpoint-308\n",
            "Configuration saved in bert-finetuned-custom-data\\checkpoint-308\\config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.23677203059196472, 'eval_f1': 0.6666666666666667, 'eval_roc_auc': 0.7758717135931381, 'eval_accuracy': 0.4264705882352941, 'eval_runtime': 0.8718, 'eval_samples_per_second': 78.003, 'eval_steps_per_second': 10.324, 'epoch': 4.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in bert-finetuned-custom-data\\checkpoint-308\\pytorch_model.bin\n",
            "tokenizer config file saved in bert-finetuned-custom-data\\checkpoint-308\\tokenizer_config.json\n",
            "Special tokens file saved in bert-finetuned-custom-data\\checkpoint-308\\special_tokens_map.json\n",
            " 50%|█████     | 385/770 [02:44<02:43,  2.35it/s]***** Running Evaluation *****\n",
            "  Num examples = 68\n",
            "  Batch size = 8\n",
            "\n",
            " 50%|█████     | 385/770 [02:45<02:43,  2.35it/s]Saving model checkpoint to bert-finetuned-custom-data\\checkpoint-385\n",
            "Configuration saved in bert-finetuned-custom-data\\checkpoint-385\\config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.22581231594085693, 'eval_f1': 0.7058823529411764, 'eval_roc_auc': 0.8062029958356641, 'eval_accuracy': 0.4852941176470588, 'eval_runtime': 0.9359, 'eval_samples_per_second': 72.66, 'eval_steps_per_second': 9.617, 'epoch': 5.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in bert-finetuned-custom-data\\checkpoint-385\\pytorch_model.bin\n",
            "tokenizer config file saved in bert-finetuned-custom-data\\checkpoint-385\\tokenizer_config.json\n",
            "Special tokens file saved in bert-finetuned-custom-data\\checkpoint-385\\special_tokens_map.json\n",
            " 60%|██████    | 462/770 [03:23<01:36,  3.20it/s]***** Running Evaluation *****\n",
            "  Num examples = 68\n",
            "  Batch size = 8\n",
            "\n",
            " 60%|██████    | 462/770 [03:24<01:36,  3.20it/s]Saving model checkpoint to bert-finetuned-custom-data\\checkpoint-462\n",
            "Configuration saved in bert-finetuned-custom-data\\checkpoint-462\\config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.21450766921043396, 'eval_f1': 0.7428571428571429, 'eval_roc_auc': 0.8330847162657717, 'eval_accuracy': 0.5588235294117647, 'eval_runtime': 0.8707, 'eval_samples_per_second': 78.094, 'eval_steps_per_second': 10.336, 'epoch': 6.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in bert-finetuned-custom-data\\checkpoint-462\\pytorch_model.bin\n",
            "tokenizer config file saved in bert-finetuned-custom-data\\checkpoint-462\\tokenizer_config.json\n",
            "Special tokens file saved in bert-finetuned-custom-data\\checkpoint-462\\special_tokens_map.json\n",
            " 65%|██████▍   | 500/770 [03:45<02:11,  2.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2534, 'learning_rate': 7.012987012987014e-06, 'epoch': 6.49}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 539/770 [03:59<01:13,  3.14it/s]***** Running Evaluation *****\n",
            "  Num examples = 68\n",
            "  Batch size = 8\n",
            "\n",
            " 70%|███████   | 539/770 [04:00<01:13,  3.14it/s]Saving model checkpoint to bert-finetuned-custom-data\\checkpoint-539\n",
            "Configuration saved in bert-finetuned-custom-data\\checkpoint-539\\config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.2099231779575348, 'eval_f1': 0.7455621301775148, 'eval_roc_auc': 0.8261855926409347, 'eval_accuracy': 0.5588235294117647, 'eval_runtime': 0.8789, 'eval_samples_per_second': 77.37, 'eval_steps_per_second': 10.24, 'epoch': 7.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in bert-finetuned-custom-data\\checkpoint-539\\pytorch_model.bin\n",
            "tokenizer config file saved in bert-finetuned-custom-data\\checkpoint-539\\tokenizer_config.json\n",
            "Special tokens file saved in bert-finetuned-custom-data\\checkpoint-539\\special_tokens_map.json\n",
            " 80%|████████  | 616/770 [04:32<00:48,  3.18it/s]***** Running Evaluation *****\n",
            "  Num examples = 68\n",
            "  Batch size = 8\n",
            "\n",
            " 80%|████████  | 616/770 [04:33<00:48,  3.18it/s]Saving model checkpoint to bert-finetuned-custom-data\\checkpoint-616\n",
            "Configuration saved in bert-finetuned-custom-data\\checkpoint-616\\config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.21168552339076996, 'eval_f1': 0.7570621468926554, 'eval_roc_auc': 0.8438374044378147, 'eval_accuracy': 0.5588235294117647, 'eval_runtime': 0.8882, 'eval_samples_per_second': 76.56, 'eval_steps_per_second': 10.133, 'epoch': 8.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in bert-finetuned-custom-data\\checkpoint-616\\pytorch_model.bin\n",
            "tokenizer config file saved in bert-finetuned-custom-data\\checkpoint-616\\tokenizer_config.json\n",
            "Special tokens file saved in bert-finetuned-custom-data\\checkpoint-616\\special_tokens_map.json\n",
            " 90%|█████████ | 693/770 [05:06<00:24,  3.18it/s]***** Running Evaluation *****\n",
            "  Num examples = 68\n",
            "  Batch size = 8\n",
            "                                                 \n",
            " 90%|█████████ | 693/770 [05:07<00:24,  3.18it/s]Saving model checkpoint to bert-finetuned-custom-data\\checkpoint-693\n",
            "Configuration saved in bert-finetuned-custom-data\\checkpoint-693\\config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.20493310689926147, 'eval_f1': 0.7586206896551724, 'eval_roc_auc': 0.8403878426253962, 'eval_accuracy': 0.5882352941176471, 'eval_runtime': 0.8885, 'eval_samples_per_second': 76.536, 'eval_steps_per_second': 10.13, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in bert-finetuned-custom-data\\checkpoint-693\\pytorch_model.bin\n",
            "tokenizer config file saved in bert-finetuned-custom-data\\checkpoint-693\\tokenizer_config.json\n",
            "Special tokens file saved in bert-finetuned-custom-data\\checkpoint-693\\special_tokens_map.json\n",
            "100%|██████████| 770/770 [05:40<00:00,  3.11it/s]***** Running Evaluation *****\n",
            "  Num examples = 68\n",
            "  Batch size = 8\n",
            "                                                 \n",
            "100%|██████████| 770/770 [05:41<00:00,  3.11it/s]Saving model checkpoint to bert-finetuned-custom-data\\checkpoint-770\n",
            "Configuration saved in bert-finetuned-custom-data\\checkpoint-770\\config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.2071578949689865, 'eval_f1': 0.7514450867052023, 'eval_roc_auc': 0.8350114985393747, 'eval_accuracy': 0.5735294117647058, 'eval_runtime': 0.9091, 'eval_samples_per_second': 74.802, 'eval_steps_per_second': 9.9, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in bert-finetuned-custom-data\\checkpoint-770\\pytorch_model.bin\n",
            "tokenizer config file saved in bert-finetuned-custom-data\\checkpoint-770\\tokenizer_config.json\n",
            "Special tokens file saved in bert-finetuned-custom-data\\checkpoint-770\\special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from bert-finetuned-custom-data\\checkpoint-693 (score: 0.7586206896551724).\n",
            "100%|██████████| 770/770 [05:48<00:00,  2.21it/s]\n",
            "Saving model checkpoint to custom_multi_label_model\n",
            "Configuration saved in custom_multi_label_model\\config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 348.6251, 'train_samples_per_second': 17.526, 'train_steps_per_second': 2.209, 'train_loss': 0.2074269183270343, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in custom_multi_label_model\\pytorch_model.bin\n",
            "tokenizer config file saved in custom_multi_label_model\\tokenizer_config.json\n",
            "Special tokens file saved in custom_multi_label_model\\special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set training arguments\n",
        "args = TrainingArguments(\n",
        "    f\"bert-finetuned-custom-data\",\n",
        "    logging_dir='./logs',\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        ")\n",
        "\n",
        "# Metrics computation function\n",
        "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "    y_pred = np.zeros(probs.shape)\n",
        "    y_pred[np.where(probs >= threshold)] = 1\n",
        "    y_true = labels\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average='micro')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    metrics = {'f1': f1_micro_average,\n",
        "               'roc_auc': roc_auc,\n",
        "               'accuracy': accuracy}\n",
        "    return metrics\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    result = multi_label_metrics(predictions=preds, labels=p.label_ids)\n",
        "    return result\n",
        "\n",
        "# Create a trainer\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the model\n",
        "trainer.save_model(\"custom_multi_label_model\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Upload the model to huggingface hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token is valid.\n",
            "Your token has been saved in your configured git credential helpers (manager-core).\n",
            "Your token has been saved to C:\\Users\\Risto Trajanov\\.cache\\huggingface\\token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in C:\\Users\\RISTOT~1\\AppData\\Local\\Temp\\tmp6w5di3i3\\config.json\n",
            "Model weights saved in C:\\Users\\RISTOT~1\\AppData\\Local\\Temp\\tmp6w5di3i3\\pytorch_model.bin\n",
            "Uploading the following files to TrajanovRisto/bert-esg: config.json,pytorch_model.bin\n",
            "pytorch_model.bin: 100%|██████████| 438M/438M [00:54<00:00, 8.10MB/s]\n",
            "Upload 1 LFS files: 100%|██████████| 1/1 [00:54<00:00, 54.10s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/TrajanovRisto/bert-esg/commit/87f83e77a864d67b4c12101642f46c501d9ce31e', commit_message='Upload BertForSequenceClassification', commit_description='', oid='87f83e77a864d67b4c12101642f46c501d9ce31e', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.push_to_hub('bert-esg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tokenizer config file saved in C:\\Users\\RISTOT~1\\AppData\\Local\\Temp\\tmpuiz_09xn\\tokenizer_config.json\n",
            "Special tokens file saved in C:\\Users\\RISTOT~1\\AppData\\Local\\Temp\\tmpuiz_09xn\\special_tokens_map.json\n",
            "Uploading the following files to TrajanovRisto/bert-esg: special_tokens_map.json,tokenizer.json,tokenizer_config.json,vocab.txt\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/TrajanovRisto/bert-esg/commit/38f5c87f95d3e294a0b78b82545f28cbded95dd0', commit_message='Upload tokenizer', commit_description='', oid='38f5c87f95d3e294a0b78b82545f28cbded95dd0', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.push_to_hub('bert-esg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Pushing split train to the Hub.\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 11.40ba/s]\n",
            "Upload 1 LFS files: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
            "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
            "Pushing split test to the Hub.\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 163.45ba/s]\n",
            "Upload 1 LFS files: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
            "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n"
          ]
        }
      ],
      "source": [
        "dataset.push_to_hub('esg-sentiment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N12WBgjFDbvs",
        "outputId": "66fe35e5-3fc1-4d78-9306-311d3109896e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input text: Some companies are investing in green technologies and reducing their environmental impact.\n",
            "Predicted labels: ['Environmental Positive']\n",
            "Input text: We are committed to supporting strong energy allies who promote democracy.\n",
            "Predicted labels: ['Social Positive', 'Governance Positive']\n",
            "Input text: Shareholders request the Company to set and publish medium- and long-term targets to reduce the greenhouse gas (GHG) emissions of the Company’s operations and energy products (Scope 1, 2, and 3) consistent with the goal of the Paris Climate Agreement: to limit global warming to well below 2°C above pre-industrial levels and to pursue efforts to limit the temperature increase to 1.5°C.\n",
            "Predicted labels: ['Environmental Positive', 'Governance Positive']\n"
          ]
        }
      ],
      "source": [
        "#tokenized_inputs = encoded_dataset[\"test\"]\n",
        "\n",
        "# Define input texts\n",
        "input_texts = [\n",
        "    \"Some companies are investing in green technologies and reducing their environmental impact.\",\n",
        "    \"We are committed to supporting strong energy allies who promote democracy.\",\n",
        "    \"Shareholders request the Company to set and publish medium- and long-term targets to reduce the greenhouse gas (GHG) emissions of the Company’s operations and energy products (Scope 1, 2, and 3) consistent with the goal of the Paris Climate Agreement: to limit global warming to well below 2°C above pre-industrial levels and to pursue efforts to limit the temperature increase to 1.5°C.\"\n",
        "]\n",
        "\n",
        "# Tokenize input texts\n",
        "input_tensor = tokenizer.batch_encode_plus(input_texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "device = model.device\n",
        "\n",
        "input_tensor = {k: v.to(device) for k, v in input_tensor.items()}\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(**input_tensor)[0]\n",
        "\n",
        "# Convert logits to probabilities using sigmoid\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "probs = sigmoid(logits)\n",
        "\n",
        "# Get predicted labels based on probabilities\n",
        "threshold = 0.5\n",
        "predicted_labels = []\n",
        "\n",
        "for i in range(len(input_texts)):\n",
        "    predictions = (probs[i] >= threshold).tolist()\n",
        "    predicted_labels.append([labels[idx] for idx, value in enumerate(predictions) if value])\n",
        "\n",
        "# Print predicted labels\n",
        "for i in range(len(input_texts)):\n",
        "    print(f\"Input text: {input_texts[i]}\")\n",
        "    print(f\"Predicted labels: {predicted_labels[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "j3AAUvxujfEH",
        "outputId": "074ef36a-f86d-481f-e164-4dc444c0e12a"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_cb550e71-9fa3-4cdb-99f3-5c26687d5ecb\", \"custom_multi_label_model.tar.gz\", 405603793)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Define the path of the model\n",
        "model_path = \"custom_multi_label_model\"\n",
        "\n",
        "# Zip the model files\n",
        "os.system(f\"tar -czf {model_path}.tar.gz {model_path}\")\n",
        "\n",
        "# Download the zipped model\n",
        "files.download(f\"{model_path}.tar.gz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dcpw_D-R73F"
      },
      "source": [
        "### Experimental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOsulNJ0FIdi"
      },
      "outputs": [],
      "source": [
        "# Read the JSON data from the file\n",
        "with open('2022data.txt', 'r') as f:\n",
        "    json_data_eval = json.load(f)\n",
        "\n",
        "# Create an empty dataframe with two columns: text and labels\n",
        "df_eval = pd.DataFrame(columns=['Text', 'labels'])\n",
        "\n",
        "# Loop through each item in the JSON data and append a new row to the dataframe\n",
        "for item in json_data_eval:\n",
        "    df_eval = df_eval.append({\n",
        "        'Text': item['text'],\n",
        "        'labels': item['labels']\n",
        "    }, ignore_index=True)\n",
        "\n",
        "# Print the resulting dataframe\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "labels_matrix = mlb.fit_transform(df_eval['labels'])\n",
        "\n",
        "# Create a new dataframe with the binary matrix and column names from the MultiLabelBinarizer\n",
        "labels_df_eval = pd.DataFrame(labels_matrix, columns=mlb.classes_)\n",
        "\n",
        "# Concatenate the new dataframe with the original dataframe\n",
        "df_eval = pd.concat([df_eval, labels_df_eval], axis=1)\n",
        "\n",
        "df_eval['sum_one_hot'] = df_eval.iloc[:, 2:].sum(axis=1)\n",
        "df_eval = df_eval[df_eval['sum_one_hot']>0]\n",
        "\n",
        "df_eval = df_eval.drop(['labels', 'sum_one_hot'], axis=1)\n",
        "\n",
        "dataset_eval = Dataset.from_pandas(df_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnJK43fwjwdo",
        "outputId": "34efbda6-05b7-416e-c5f2-f4f3a851ed68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Social Positive', 'Governance Positive']\n"
          ]
        }
      ],
      "source": [
        "# Test the model on a new example\n",
        "example_text = \"We are committed to supporting strong energy allies who promote democracy.\"\n",
        "input_tensor = tokenizer.encode_plus(example_text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "# Move the input tensor to the same device as the model\n",
        "input_tensor = {k: v.to(device) for k, v in input_tensor.items()}\n",
        "\n",
        "logits = model(**input_tensor).logits\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "probs = sigmoid(logits)\n",
        "\n",
        "threshold = 0.45\n",
        "predictions = (probs >= threshold).tolist()[0]\n",
        "\n",
        "predicted_labels = [labels[idx] for idx, value in enumerate(predictions) if value]\n",
        "\n",
        "print(predicted_labels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0fad0845d75c414ab9008499e02fd22f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1da97a22a3124fa4bcdac07e755b9d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f85148fdcbc442a0ae07bd72a1734b92",
            "placeholder": "​",
            "style": "IPY_MODEL_37919a76128745b3b068805483e6f5f9",
            "value": "Map: 100%"
          }
        },
        "2274c90baa1e4bf69fcd2efbb3b7b1a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e2803a3b918404e93cfa17545ddbd93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37919a76128745b3b068805483e6f5f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c794ab0e38f4afcb8095e4a801f6ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e2803a3b918404e93cfa17545ddbd93",
            "placeholder": "​",
            "style": "IPY_MODEL_8da663ef0a914383852cedbbe358f3f9",
            "value": "Map:   0%"
          }
        },
        "4ab43117e93d4baf946961aeb08fca93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5baaa3c512594058821c3e58406c9fa6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "5ef4ef9e2b98458ebb4a93188d32f204": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62fd68a5ea564c509a0ae7a66979b172": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0c2538c491b46d796ed0d17ea37b9ae",
            "max": 611,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ff3243dc1964d869e7d32995ca80c21",
            "value": 611
          }
        },
        "737f306e12214ea485baafc4812da102": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2274c90baa1e4bf69fcd2efbb3b7b1a8",
            "placeholder": "​",
            "style": "IPY_MODEL_ca72659a41874f51a169595636ca62e4",
            "value": " 611/611 [00:00&lt;00:00, 4128.74 examples/s]"
          }
        },
        "7ff3243dc1964d869e7d32995ca80c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8da663ef0a914383852cedbbe358f3f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0c2538c491b46d796ed0d17ea37b9ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca72659a41874f51a169595636ca62e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf23db3bcf2d41bd96a17da6b9a6e6f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de361c7c877b41af82e65851fe6f9392": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf23db3bcf2d41bd96a17da6b9a6e6f5",
            "max": 68,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ab43117e93d4baf946961aeb08fca93",
            "value": 68
          }
        },
        "e0b9094c0b744be4aea290900eb2f88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1da97a22a3124fa4bcdac07e755b9d70",
              "IPY_MODEL_62fd68a5ea564c509a0ae7a66979b172",
              "IPY_MODEL_737f306e12214ea485baafc4812da102"
            ],
            "layout": "IPY_MODEL_e17b08b22be04e8a9eea8a14eba2acc7"
          }
        },
        "e17b08b22be04e8a9eea8a14eba2acc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "ef894fd2d7a6448191d19a98baec1510": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fad0845d75c414ab9008499e02fd22f",
            "placeholder": "​",
            "style": "IPY_MODEL_5ef4ef9e2b98458ebb4a93188d32f204",
            "value": " 0/68 [00:00&lt;?, ? examples/s]"
          }
        },
        "f85148fdcbc442a0ae07bd72a1734b92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9f7136b1ec04d7e9e166f32e77fdc49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c794ab0e38f4afcb8095e4a801f6ed2",
              "IPY_MODEL_de361c7c877b41af82e65851fe6f9392",
              "IPY_MODEL_ef894fd2d7a6448191d19a98baec1510"
            ],
            "layout": "IPY_MODEL_5baaa3c512594058821c3e58406c9fa6"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
